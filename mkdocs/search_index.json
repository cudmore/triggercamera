{
    "docs": [
        {
            "location": "/", 
            "text": "Trigger Camera\n\n\nThis is a Raspberry Pi camera that responds to general purpose digital input-output (GPIO) pulses to start and stop video acquisition during an experiment. During video acquisition, external events such as frame times on a scanning microscope are watermarked on the video and saved to a text file. The camera can be controlled from a Python command prompt, via a web browser, or using a hardware LCD/keypad.\n\n\nOverview\n\n\nBackground on the Raspberry Pi\n\n\nThe Raspberry Pi is a low cost ($35) computer that runs Linux. In addition to USB, ethernet, and HDMI connectors, the Raspberry Pi has a dedicated camera port and GPIO ports. Both the camera and GPIO ports can be easily programmed using Python. The Raspberry Pi provides an end-to-end open source system. Both the hardware and the software is provided by \nThe Raspberry Pi Foundation\n and is actively maintained and extended by an active developer community.\n\n\nSoftware implementation\n\n\nThe software provided here will run a Raspberry Pi camera as a slave to other devices already in place for an experiment. Once the camera is armed, it will continuously record a circular stream of video in memory. When a digital trigger is received, the the video will begin being saved to disk. In addition to saving the video after a trigger, the video before the trigger will also be saved. This has the distinct advantage of given you a record of what your animal was doing  before a trial was started. In many cases, 'bad trials' can be found because there was a lot of movement (or some other abberent event) before a trial began.\n\n\nLimitations\n\n\nThe Raspberry Pi runs Linux and like other operating systems including Microsoft Windows and Mac OS it is not real time. There will always be unpredictable delays in the detection and generation of GPIO pulses. If the detection of a fast pulse or the timing of a pulse is critical for an experiment it is strongly suggested to use a more precise microcontroller like an Arduino.\n\n\nSee the \nAnalysis\n section for example Python code to test the limits of this precision.\n\n\nTTL versus GPIO\n\n\nTransistor\u2013transistor logic (TTL) and general-purpose input/output (GPIO) are both digital lines that transmit signals by pulsing between a low level (usually 0 or ground) and a high level. Although it is actually rather complicated, the main difference between TTL and GPIO is in the high-level. Most devices with TTL input/output use a 5V high level while the Raspberry Pi GPIO uses a 3.5V high level. The Raspberry Pi 3.5V GPIO are \nnot\n 5V tolerant. If a 5V TTL is connected directly to a Raspberry Pi 3.5V GPIO, the Raspberry Pi may be burned and no longer function. To connect a 5V TTL device to a Raspberry Pi 3.5V GPIO, the voltage needs to be shifted down to 3.5V. This is easily accomplished with a pre-made \nlevel shifter\n or by \nhand-wiring a voltage-divider\n.\n\n\nParts list\n\n\nThe total cost should be about $150. These parts are widely available at many different online sellers including: Sparkfun, Adafruit, Element14, and Amazon.\n\n\n\n\n\n\n\n\nQuatity\n\n\nItem\n\n\nNote\n\n\nCost\n\n\nLink\n\n\n\n\n\n\n\n\n\n\n1\n\n\nRaspberry Pi 2 or 3\n\n\nEither 2 or 3 is fine\n\n\n$35-$40\n\n\nelement14\nadafruit\n\n\n\n\n\n\n1\n\n\nClass 10 micro SD card\n\n\nFor the Rasperry system, 16 GB is fine\n\n\n$10\n\n\nlink\n\n\n\n\n\n\n1\n\n\n5V 2A AC to DC power\n\n\nMake sure it is \n2A and don't buy a cheap one\n\n\n$6-$8\n\n\nlink\n\n\n\n\n\n\n1\n\n\nPi NoIR Camera\n\n\n\n\n$25-$30\n\n\nlink\n\n\n\n\n\n\n1\n\n\nPi Camera Ribbon cable (2 meters)\n\n\n\n\n$6\n\n\nlink\n\n\n\n\n\n\n1\n\n\nPi Camera HDMI extension cable\n\n\nOptional\n\n\n$15\n\n\nlink\n\n\n\n\n\n\n1\n\n\nUSB Memory\n\n\nTo save video, 32GB or 64GB is a good starting point\n\n\n$10-$15\n\n\nlink\n\n\n\n\n\n\n1\n\n\nVoltage level shifter\n\n\nTo convert 5V GPIO to 3.5V\n\n\n$4\n\n\nlink\n\n\n\n\n\n\n4\n\n\nIR LEDS\n\n\n900nm is best\n\n\n$0.95\n\n\n850nm\n/\n950nm\n\n\n\n\n\n\n4\n\n\nxxx Ohm resistors\n\n\nOne for each IR LED\n\n\n$7 (for 500 pack)\n\n\nlink\n\n\n\n\n\n\n1\n\n\n5V relay\n\n\nTo turn higher voltages like 12V on and off\n\n\n$3\n\n\nlink\n\n\n\n\n\n\n\n\nOne option is to buy a Raspberry Pi starter kit from \nCanakit\n. These kits include most of the parts needed to get a fully working Raspberry Pi.\n\n\nThe number of IR LEDs is not critical. This will depend on how far away your subject is from the camera. Usually 4 IR LEDs is a good starting point.\n\n\nConfiguring a Raspberry Pi\n\n\nWe are not going to provide a full tutorial here and will assume a functioning Raspberry Pi. Here is a basic to do list to get started.\n\n\n\n\nInstall Raspbian on an SD card and boot the pi\n\n\nConfigure wired network\n\n\nMake sure the camera is installed\n\n\nInstall the \niPython\n command line interface\n\n\nInstall required python libraries\n\n\nMount a USB drive at boot\n\n\nSMB to mount/share folders with Windows computers\n\n\nAFP to mount/share folders with OS X (SMB will also work with OS X)\n\n\nStartUpMailer to have the Raspberry Pi email with its IP address when it boots\n\n\n\n\nBuilding the system\n\n\nChoosing the triggers\n\n\nThere are two different trigger options. These are set in the \nconfig.ini\n file using \nuseTwoTriggerPins: 1\n\n\n\n\nTwo trigger pins, one for triggering start/stop of video and a second for triggering frames. This is the preferred triggering system. This is used to interface with a \nBruker\n microscope.\n\n\nOne trigger pin for both trigger and frames. This is used to interface with a microscope running \nScanImage\n software.\n\n\n\n\nWiring the system\n\n\n\n\nConnect camera to Raspberry Pi\n\n\nConnect signal and ground of GPIO/TTL cables from other equipment to the Raspberry Pi (be sure to convert incoming 5V GPIO to 3.5V)\n\n\nConnect IR LEDs to the Raspberry Pi. If LEDs need a lot of power, hook them up with a 5V relay and an external 12V power supply.\n\n\n\n\n**Important:**\n The Raspberry Pi can only accept GPIO signals at 3.5V. Many devices use 5V for GPIO/TTL signals. Thus, a level shifter is needed to convert 5V to 3.5V. It is easy to make a \nvoltage divider\n by hand or to buy a pre-made \nvoltage level shifter\n.\n\n\nInstalling required Python libraries\n\n\nPython interface\n\n\nRPi.GPIO\npicamera\nConfigParser\n\n\n\nWeb Interface\n\n\nflask\nflask-socketio\n\n\n\nRunning the camera\n\n\nAnalog video output\n\n\nThe primary interface for controlling the camera is through either Python or a web browser. An added feature is the real-time video can be output on the analog RCA plug on the Raspberry Pi. By connecting this RCA plug to an external video monitor (not a computer monitor), a live video feed can be viewed. Using this live video feed does not interfere with any of the Python or web browser code that interacts with the camera to trigger and save video.\n\n\nto do:\n The Raspberry Pi 2/3 uses a 3.5mm audio plug for both audio and composite video out. See \nhere\n.\n\n\nPython command line\n\n\nThe \niPython\n command line interface should be used.\n\n\nWith \ntriggercamera.py\n, the camera can be controlled with a Python command line. Once the camera is armed with 'ArmTrigger()' it will start and stop video recording following GPIO triggers.\n\n\nimport triggercamera\ntc=triggercamera.TriggerCamera()\ntc.ArmTrigger()\n\n\n\nAdditional interface\n\n\n#start and stop video recording as much as you like\ntc.startVideo()\ntc.stopVideo()\n\n# single images can be saved every few seconds while video is being recorded\ntc.doTimelapse=1\ntc.doTimelapse=0\n\n# todo: add interface to control two different LEDs\n\n\n\nWeb interface\n\n\ntriggercamera_app.py\n provides a web server allowing the camera to be controlled through a web browser. The web server is run using \nFlask\n and provides a REST api as a wrapper to interact with the triggercamera.py Python code.\n\n\nRun a web server with\n\n\npython triggercamera_app.py\n\n\n\nThe server will be available on the local IP address of the machine running the code, in this case '192.168.1.12'. The server will run on port 5010.\n\n\nThe camera can be controlled through a web browser as follows.\n\n\nhttp://192.168.1.12:5010/startarm\nhttp://192.168.1.12:5010/stoparm\nhttp://192.168.1.12:5010/startvideo\nhttp://192.168.1.12:5010/stopvideo\nhttp://192.168.1.12:5010/timelapseon\nhttp://192.168.1.12:5010/timelapseoff\nhttp://192.168.1.12:5010/lastimage\n\n\n\nLCD and keypad interface\n\n\nNOT IMPLEMENTED.\n A hardware interface is provided if an \nLCD/keypad\n is attached to the Raspberry Pi.\n\n\nUser configuration\n\n\nModify \nconfig.ini\n and restart the camera code\n\n\n[triggers]\nuseTwoTriggerPins: True\ntriggerpin: 4\nframepin: 17\n\n[led]\nled1pin: 2\nled2pin: 3\n\n[camera]\nfps: 30\nresolution: 640,480\nbufferSeconds = 5\n\nwatchedpathon: 1\nwatchedpath: /video\n\nsavepath: /video\n\n\n\nOutput video\n\n\nTrigger camera saves video in the \nh264\n video format. This is a very efficient video codec that make very small but highly detailed videos. Before these h264 video files can be analyzed, they need to be converted to include the frames per second. This can be done in a number of video editing programs. One way to do this conversion is by using the command line program \nffmpeg\n. Because ffmpeg can be scripted, it is easy to incorporated into most workflows.\n\n\nsrcDir = '/src/dir/with/video'\ndstDir = 'dst/dir/for/mp4'\nfor file in srcDir:\n    outfile = file.strip('h264') + '.mp4'\n    ffmpeg -r 25 -i file dstDir+outfile\n\n\n\nOutput files\n\n\nIn addition to saving video, Trigger Camera also saves a .txt file for each video with frame time stamps.\n\n\nHere are the first 5 frames of an output .txt file\n\n\ndate,time,seconds,frame\n20160520,074319.0,1463744599.61,1\n20160520,074319.0,1463744599.65,2\n20160520,074319.0,1463744599.68,3\n20160520,074319.0,1463744599.71,4\n20160520,074319.0,1463744599.74,5\n\n\n\nAnalysis\n\n\nAnalyzing output .txt files\n\n\nWe have provided Python code to load, analyze and plot the output .txt files. See \nan example iPython notebook\n. Because the Raspberry Pi is not configured with a keyboard/mouse/monitor, this code can be run on a different machine using an iPython notebook.\n\n\nBring up an iPython web interface\n\n\n# if your Raspberry Pi is on the network at 'pi60'\ncd /Volumes/pi60/Sites/triggercamera/analysis/\nipython notebook\n\n\n\n\n\nAnalyzing video\n\n\nWe will provide Python code using \nOpenCV\n to load and browse video files.\n\n\nAdd ons\n\n\nBy creating a system with a Raspberry Pi there are a large number of ways to quickly and cheaply extend the system in very useful ways.\n\n\n\n\nAdd an Arduino microcontroller\n\n\nAdd an LCD/button controller\n\n\nAdd a touch-screen interface\n\n\n\n\nTroubleshooting\n\n\n\n\n\n\nTest the camera with\n\n\nraspistill -o tst.jpg\n\n\n\n\n\n\nIf the camera triggering is erratic or the Raspberry is missing fast pulses, check that all digital lines going to the Raspberry Pi are grounded. It is good practice to connect the Raspberry Pi ground pins to the ground (shield) of any digital lines.\n\n\n\n\n\n\nIf the recorded video changes light-levels erratically, this is usllay due to fluctuations in the power to the Pi. Make sure the Pi has a DC power supply \n2 Amps. If additional LEDs are being powered by the Pi, consider breaking these out with their own dedicated power supplies.\n\n\n\n\n\n\nSee this to auto mount an SMB share on boot\n\n\n\n\n\n\nhttp://raspberrypi.stackexchange.com/questions/34444/cant-get-a-cifs-network-drive-to-mount-on-boot\n\n\nTo Do\n\n\n\n\nImplement a Flask homepage to provide buttons to control camera and feedback during a trial.\n\n\nAdd control and interface for two LEDs (e.g. IR and white).\n\n\nAdd a header to output files #fps=xxx;width=xxx;height=xxx\n\n\nWrite a Python script to batch process a folder of .h264 into .mp4 (with fps)\n\n\ntry using easydict so i can use'.' notation in code\n\n\nAdd a physical emergency 'stop' button", 
            "title": "home"
        }, 
        {
            "location": "/#trigger-camera", 
            "text": "This is a Raspberry Pi camera that responds to general purpose digital input-output (GPIO) pulses to start and stop video acquisition during an experiment. During video acquisition, external events such as frame times on a scanning microscope are watermarked on the video and saved to a text file. The camera can be controlled from a Python command prompt, via a web browser, or using a hardware LCD/keypad.", 
            "title": "Trigger Camera"
        }, 
        {
            "location": "/#overview", 
            "text": "", 
            "title": "Overview"
        }, 
        {
            "location": "/#background-on-the-raspberry-pi", 
            "text": "The Raspberry Pi is a low cost ($35) computer that runs Linux. In addition to USB, ethernet, and HDMI connectors, the Raspberry Pi has a dedicated camera port and GPIO ports. Both the camera and GPIO ports can be easily programmed using Python. The Raspberry Pi provides an end-to-end open source system. Both the hardware and the software is provided by  The Raspberry Pi Foundation  and is actively maintained and extended by an active developer community.", 
            "title": "Background on the Raspberry Pi"
        }, 
        {
            "location": "/#software-implementation", 
            "text": "The software provided here will run a Raspberry Pi camera as a slave to other devices already in place for an experiment. Once the camera is armed, it will continuously record a circular stream of video in memory. When a digital trigger is received, the the video will begin being saved to disk. In addition to saving the video after a trigger, the video before the trigger will also be saved. This has the distinct advantage of given you a record of what your animal was doing  before a trial was started. In many cases, 'bad trials' can be found because there was a lot of movement (or some other abberent event) before a trial began.", 
            "title": "Software implementation"
        }, 
        {
            "location": "/#limitations", 
            "text": "The Raspberry Pi runs Linux and like other operating systems including Microsoft Windows and Mac OS it is not real time. There will always be unpredictable delays in the detection and generation of GPIO pulses. If the detection of a fast pulse or the timing of a pulse is critical for an experiment it is strongly suggested to use a more precise microcontroller like an Arduino.  See the  Analysis  section for example Python code to test the limits of this precision.", 
            "title": "Limitations"
        }, 
        {
            "location": "/#ttl-versus-gpio", 
            "text": "Transistor\u2013transistor logic (TTL) and general-purpose input/output (GPIO) are both digital lines that transmit signals by pulsing between a low level (usually 0 or ground) and a high level. Although it is actually rather complicated, the main difference between TTL and GPIO is in the high-level. Most devices with TTL input/output use a 5V high level while the Raspberry Pi GPIO uses a 3.5V high level. The Raspberry Pi 3.5V GPIO are  not  5V tolerant. If a 5V TTL is connected directly to a Raspberry Pi 3.5V GPIO, the Raspberry Pi may be burned and no longer function. To connect a 5V TTL device to a Raspberry Pi 3.5V GPIO, the voltage needs to be shifted down to 3.5V. This is easily accomplished with a pre-made  level shifter  or by  hand-wiring a voltage-divider .", 
            "title": "TTL versus GPIO"
        }, 
        {
            "location": "/#parts-list", 
            "text": "The total cost should be about $150. These parts are widely available at many different online sellers including: Sparkfun, Adafruit, Element14, and Amazon.     Quatity  Item  Note  Cost  Link      1  Raspberry Pi 2 or 3  Either 2 or 3 is fine  $35-$40  element14 adafruit    1  Class 10 micro SD card  For the Rasperry system, 16 GB is fine  $10  link    1  5V 2A AC to DC power  Make sure it is  2A and don't buy a cheap one  $6-$8  link    1  Pi NoIR Camera   $25-$30  link    1  Pi Camera Ribbon cable (2 meters)   $6  link    1  Pi Camera HDMI extension cable  Optional  $15  link    1  USB Memory  To save video, 32GB or 64GB is a good starting point  $10-$15  link    1  Voltage level shifter  To convert 5V GPIO to 3.5V  $4  link    4  IR LEDS  900nm is best  $0.95  850nm / 950nm    4  xxx Ohm resistors  One for each IR LED  $7 (for 500 pack)  link    1  5V relay  To turn higher voltages like 12V on and off  $3  link     One option is to buy a Raspberry Pi starter kit from  Canakit . These kits include most of the parts needed to get a fully working Raspberry Pi.  The number of IR LEDs is not critical. This will depend on how far away your subject is from the camera. Usually 4 IR LEDs is a good starting point.", 
            "title": "Parts list"
        }, 
        {
            "location": "/#configuring-a-raspberry-pi", 
            "text": "We are not going to provide a full tutorial here and will assume a functioning Raspberry Pi. Here is a basic to do list to get started.   Install Raspbian on an SD card and boot the pi  Configure wired network  Make sure the camera is installed  Install the  iPython  command line interface  Install required python libraries  Mount a USB drive at boot  SMB to mount/share folders with Windows computers  AFP to mount/share folders with OS X (SMB will also work with OS X)  StartUpMailer to have the Raspberry Pi email with its IP address when it boots", 
            "title": "Configuring a Raspberry Pi"
        }, 
        {
            "location": "/#building-the-system", 
            "text": "", 
            "title": "Building the system"
        }, 
        {
            "location": "/#choosing-the-triggers", 
            "text": "There are two different trigger options. These are set in the  config.ini  file using  useTwoTriggerPins: 1   Two trigger pins, one for triggering start/stop of video and a second for triggering frames. This is the preferred triggering system. This is used to interface with a  Bruker  microscope.  One trigger pin for both trigger and frames. This is used to interface with a microscope running  ScanImage  software.", 
            "title": "Choosing the triggers"
        }, 
        {
            "location": "/#wiring-the-system", 
            "text": "Connect camera to Raspberry Pi  Connect signal and ground of GPIO/TTL cables from other equipment to the Raspberry Pi (be sure to convert incoming 5V GPIO to 3.5V)  Connect IR LEDs to the Raspberry Pi. If LEDs need a lot of power, hook them up with a 5V relay and an external 12V power supply.   **Important:**  The Raspberry Pi can only accept GPIO signals at 3.5V. Many devices use 5V for GPIO/TTL signals. Thus, a level shifter is needed to convert 5V to 3.5V. It is easy to make a  voltage divider  by hand or to buy a pre-made  voltage level shifter .", 
            "title": "Wiring the system"
        }, 
        {
            "location": "/#installing-required-python-libraries", 
            "text": "", 
            "title": "Installing required Python libraries"
        }, 
        {
            "location": "/#python-interface", 
            "text": "RPi.GPIO\npicamera\nConfigParser", 
            "title": "Python interface"
        }, 
        {
            "location": "/#web-interface", 
            "text": "flask\nflask-socketio", 
            "title": "Web Interface"
        }, 
        {
            "location": "/#running-the-camera", 
            "text": "", 
            "title": "Running the camera"
        }, 
        {
            "location": "/#analog-video-output", 
            "text": "The primary interface for controlling the camera is through either Python or a web browser. An added feature is the real-time video can be output on the analog RCA plug on the Raspberry Pi. By connecting this RCA plug to an external video monitor (not a computer monitor), a live video feed can be viewed. Using this live video feed does not interfere with any of the Python or web browser code that interacts with the camera to trigger and save video.  to do:  The Raspberry Pi 2/3 uses a 3.5mm audio plug for both audio and composite video out. See  here .", 
            "title": "Analog video output"
        }, 
        {
            "location": "/#python-command-line", 
            "text": "The  iPython  command line interface should be used.  With  triggercamera.py , the camera can be controlled with a Python command line. Once the camera is armed with 'ArmTrigger()' it will start and stop video recording following GPIO triggers.  import triggercamera\ntc=triggercamera.TriggerCamera()\ntc.ArmTrigger()  Additional interface  #start and stop video recording as much as you like\ntc.startVideo()\ntc.stopVideo()\n\n# single images can be saved every few seconds while video is being recorded\ntc.doTimelapse=1\ntc.doTimelapse=0\n\n# todo: add interface to control two different LEDs", 
            "title": "Python command line"
        }, 
        {
            "location": "/#web-interface_1", 
            "text": "triggercamera_app.py  provides a web server allowing the camera to be controlled through a web browser. The web server is run using  Flask  and provides a REST api as a wrapper to interact with the triggercamera.py Python code.  Run a web server with  python triggercamera_app.py  The server will be available on the local IP address of the machine running the code, in this case '192.168.1.12'. The server will run on port 5010.  The camera can be controlled through a web browser as follows.  http://192.168.1.12:5010/startarm\nhttp://192.168.1.12:5010/stoparm\nhttp://192.168.1.12:5010/startvideo\nhttp://192.168.1.12:5010/stopvideo\nhttp://192.168.1.12:5010/timelapseon\nhttp://192.168.1.12:5010/timelapseoff\nhttp://192.168.1.12:5010/lastimage", 
            "title": "Web interface"
        }, 
        {
            "location": "/#lcd-and-keypad-interface", 
            "text": "NOT IMPLEMENTED.  A hardware interface is provided if an  LCD/keypad  is attached to the Raspberry Pi.", 
            "title": "LCD and keypad interface"
        }, 
        {
            "location": "/#user-configuration", 
            "text": "Modify  config.ini  and restart the camera code  [triggers]\nuseTwoTriggerPins: True\ntriggerpin: 4\nframepin: 17\n\n[led]\nled1pin: 2\nled2pin: 3\n\n[camera]\nfps: 30\nresolution: 640,480\nbufferSeconds = 5\n\nwatchedpathon: 1\nwatchedpath: /video\n\nsavepath: /video", 
            "title": "User configuration"
        }, 
        {
            "location": "/#output-video", 
            "text": "Trigger camera saves video in the  h264  video format. This is a very efficient video codec that make very small but highly detailed videos. Before these h264 video files can be analyzed, they need to be converted to include the frames per second. This can be done in a number of video editing programs. One way to do this conversion is by using the command line program  ffmpeg . Because ffmpeg can be scripted, it is easy to incorporated into most workflows.  srcDir = '/src/dir/with/video'\ndstDir = 'dst/dir/for/mp4'\nfor file in srcDir:\n    outfile = file.strip('h264') + '.mp4'\n    ffmpeg -r 25 -i file dstDir+outfile", 
            "title": "Output video"
        }, 
        {
            "location": "/#output-files", 
            "text": "In addition to saving video, Trigger Camera also saves a .txt file for each video with frame time stamps.  Here are the first 5 frames of an output .txt file  date,time,seconds,frame\n20160520,074319.0,1463744599.61,1\n20160520,074319.0,1463744599.65,2\n20160520,074319.0,1463744599.68,3\n20160520,074319.0,1463744599.71,4\n20160520,074319.0,1463744599.74,5", 
            "title": "Output files"
        }, 
        {
            "location": "/#analysis", 
            "text": "", 
            "title": "Analysis"
        }, 
        {
            "location": "/#analyzing-output-txt-files", 
            "text": "We have provided Python code to load, analyze and plot the output .txt files. See  an example iPython notebook . Because the Raspberry Pi is not configured with a keyboard/mouse/monitor, this code can be run on a different machine using an iPython notebook.  Bring up an iPython web interface  # if your Raspberry Pi is on the network at 'pi60'\ncd /Volumes/pi60/Sites/triggercamera/analysis/\nipython notebook", 
            "title": "Analyzing output .txt files"
        }, 
        {
            "location": "/#analyzing-video", 
            "text": "We will provide Python code using  OpenCV  to load and browse video files.", 
            "title": "Analyzing video"
        }, 
        {
            "location": "/#add-ons", 
            "text": "By creating a system with a Raspberry Pi there are a large number of ways to quickly and cheaply extend the system in very useful ways.   Add an Arduino microcontroller  Add an LCD/button controller  Add a touch-screen interface", 
            "title": "Add ons"
        }, 
        {
            "location": "/#troubleshooting", 
            "text": "Test the camera with  raspistill -o tst.jpg    If the camera triggering is erratic or the Raspberry is missing fast pulses, check that all digital lines going to the Raspberry Pi are grounded. It is good practice to connect the Raspberry Pi ground pins to the ground (shield) of any digital lines.    If the recorded video changes light-levels erratically, this is usllay due to fluctuations in the power to the Pi. Make sure the Pi has a DC power supply  2 Amps. If additional LEDs are being powered by the Pi, consider breaking these out with their own dedicated power supplies.    See this to auto mount an SMB share on boot    http://raspberrypi.stackexchange.com/questions/34444/cant-get-a-cifs-network-drive-to-mount-on-boot", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/#to-do", 
            "text": "Implement a Flask homepage to provide buttons to control camera and feedback during a trial.  Add control and interface for two LEDs (e.g. IR and white).  Add a header to output files #fps=xxx;width=xxx;height=xxx  Write a Python script to batch process a folder of .h264 into .mp4 (with fps)  try using easydict so i can use'.' notation in code  Add a physical emergency 'stop' button", 
            "title": "To Do"
        }, 
        {
            "location": "/dev/", 
            "text": "PlatformIO\n\n\nplatformio run --target upload\n\nplatformio run --target clean\n\nplatformio serialports monitor -p /dev/ttyACM0 -b 115200 #a serial port monitor\n\n\n\nmkDocs\n\n\npip install mkdocs\npip install mkdocs-cinder\n\nmkdocs serve\nmkdocs serve --dev-addr=0.0.0.0:8000 # serves built site on LAN IP\n\n\n\n\n\nmkdocs new [dir-name]\n - Create a new project.\n\n\nmkdocs serve\n - Start the live-reloading docs server.\n\n\nmkdocs build\n - Build the documentation site.\n\n\nmkdocs help\n - Print this help message.\n\n\n\n\nDeploy to github\n\n\nmkdocs gh-deploy will use the gh-pages branch of repository specified in mkdocs.yml\n\n\n# this will deploy to github gh-pages specified in mkdocs.yml\ncd tiggercamera #should have mkdocs.yml file\nmkdocs build --clean\nmkdocs gh-deploy --clean \n#site is then available at\nhttp://cudmore.github.io/triggercamera\n\n\n\nProject layout\n\n\nmkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.", 
            "title": "dev"
        }, 
        {
            "location": "/dev/#platformio", 
            "text": "platformio run --target upload\n\nplatformio run --target clean\n\nplatformio serialports monitor -p /dev/ttyACM0 -b 115200 #a serial port monitor", 
            "title": "PlatformIO"
        }, 
        {
            "location": "/dev/#mkdocs", 
            "text": "pip install mkdocs\npip install mkdocs-cinder\n\nmkdocs serve\nmkdocs serve --dev-addr=0.0.0.0:8000 # serves built site on LAN IP   mkdocs new [dir-name]  - Create a new project.  mkdocs serve  - Start the live-reloading docs server.  mkdocs build  - Build the documentation site.  mkdocs help  - Print this help message.", 
            "title": "mkDocs"
        }, 
        {
            "location": "/dev/#deploy-to-github", 
            "text": "mkdocs gh-deploy will use the gh-pages branch of repository specified in mkdocs.yml  # this will deploy to github gh-pages specified in mkdocs.yml\ncd tiggercamera #should have mkdocs.yml file\nmkdocs build --clean\nmkdocs gh-deploy --clean \n#site is then available at\nhttp://cudmore.github.io/triggercamera", 
            "title": "Deploy to github"
        }, 
        {
            "location": "/dev/#project-layout", 
            "text": "mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.", 
            "title": "Project layout"
        }
    ]
}